{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b832dcf-f740-4a94-bbdc-adfefb58f750",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55381626-ba36-4dcb-a364-056051a53e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the dataset from the .zip file\n",
    "from os import walk\n",
    "import zipfile\n",
    "\n",
    "# Get the execution times\n",
    "import time\n",
    "\n",
    "# Work with the dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Work with the machine learning models\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3e25b-069c-4335-874d-4b97b16911cc",
   "metadata": {},
   "source": [
    "# Setting default values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7601be-55ee-4b0f-9274-a684e30de0c3",
   "metadata": {},
   "source": [
    "Setting some default values to be used all over the code.\n",
    "\n",
    "The values below could be changed if you are experiencing problems of performance or memory problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e02ecc-f23d-4f2d-9bcf-288a5db24038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to fill the random state of some functions\n",
    "SEED = 50\n",
    "\n",
    "# The number of samples to be used during the machine learning model training\n",
    "# If you are having memory problems you could try to reduce this number\n",
    "N_SAMPLES = 10000\n",
    "\n",
    "# Limits the number of values of the inital dataframe\n",
    "# A value of less than 1 means to get all the dataset\n",
    "DF_LIMIT = -1\n",
    "\n",
    "# The number of jobs to run in parallel when available\n",
    "# -1 means all processors available\n",
    "# It's better not to use all processors, we had memory leaks while using it because of GridSearchCV\n",
    "N_JOBS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6e341-9299-413a-986f-69c1f11204ae",
   "metadata": {},
   "source": [
    "# Extracting and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e8c71a-c8c9-408a-80c9-cb198ac32f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the .zip file and get the path to extract it\n",
    "dataset_folder = './dataset'\n",
    "    \n",
    "filenames = next(walk(dataset_folder), (_, _, []))[2]\n",
    "zip_filename = [filename for filename in filenames if filename.find('.zip') > -1][0]\n",
    "file_path = dataset_folder + '/' + zip_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c681d2d-6928-45f6-9d53-ec2495ad6c6b",
   "metadata": {},
   "source": [
    "You only need to run the code cell below if you put solely the .zip file insede the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37422ac7-dbd9-4634-8f5f-c214a32fae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the contents of the .zip file inside the dataset folder\n",
    "# Extract the file only if there isn't the .txt file inside the folder already\n",
    "has_txt_dataset = np.sum([True for filename in filenames if filename.find('.txt') > -1]) > 0\n",
    "\n",
    "if not has_txt_dataset:\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d30582f-4c2c-4b01-80d9-135a0f0897eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the .txt dataset file path extracted at the previous step\n",
    "filenames = next(walk(dataset_folder), (_, _, []))[2]\n",
    "dataset_filename = [filename for filename in filenames if filename.find('.txt') > -1][0]\n",
    "dataset_path = dataset_folder + '/' + dataset_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22937b4-a45b-473d-beeb-a26556e935d9",
   "metadata": {},
   "source": [
    "To load the dataset inside a Pandas DataFrame we had to put the delimiter to be a TAB (\\t) because it is how the data is separated inside the .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9028708-12f1-4a42-bdfc-5021e6c4f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path, delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499a2e1-72c0-4d9d-9b9b-7afecef6b07f",
   "metadata": {},
   "source": [
    "The cell below gets a subset of rows from the original dataset to make it easier to work with the data.\n",
    "\n",
    "It had to get the subset sequentially because the dataset is organized in a time based way and we need to respect this to make some transformations later on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30971f52-cf62-4b40-8b25-cce03834bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DF_LIMIT > 0:\n",
    "    df = df[:DF_LIMIT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f4f1a8-1a9d-4af5-adf1-1b72213bd8bb",
   "metadata": {},
   "source": [
    "# Analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d88c548-17d6-4026-9360-95211cb29d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451003, 57)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3335f17-24a0-4c69-a39f-9c296d31c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>Sample Name</th>\n",
       "      <th>Transaction Id</th>\n",
       "      <th>Anon Student Id</th>\n",
       "      <th>Session Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Time Zone</th>\n",
       "      <th>Duration (sec)</th>\n",
       "      <th>Student Response Type</th>\n",
       "      <th>Student Response Subtype</th>\n",
       "      <th>...</th>\n",
       "      <th>KC (MCAS5-State_WPI-Simple)</th>\n",
       "      <th>KC Category (MCAS5-State_WPI-Simple)</th>\n",
       "      <th>KC (MCAS5-State_WPI-Simple).1</th>\n",
       "      <th>KC Category (MCAS5-State_WPI-Simple).1</th>\n",
       "      <th>KC (Single-KC)</th>\n",
       "      <th>KC Category (Single-KC)</th>\n",
       "      <th>KC (Unique-step)</th>\n",
       "      <th>KC Category (Unique-step)</th>\n",
       "      <th>School</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>All Data</td>\n",
       "      <td>13cb29890fa2be0ca31bcd07f35000d6</td>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>2006-10-13 11:53:10</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>22</td>\n",
       "      <td>ATTEMPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single-KC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>All Data</td>\n",
       "      <td>3fedf6c06ab6b9b3c36e245335445bcf</td>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>2006-10-13 11:53:13</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>3</td>\n",
       "      <td>HINT_REQUEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single-KC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>All Data</td>\n",
       "      <td>0f5bb1a5c133ac1aa0a3d32e4d44dde9</td>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>2006-10-13 11:53:20</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>7</td>\n",
       "      <td>HINT_REQUEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single-KC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>All Data</td>\n",
       "      <td>19a9aabf614d6f27dc9970dc842da081</td>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>2006-10-13 11:53:22</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>2</td>\n",
       "      <td>HINT_REQUEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single-KC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>All Data</td>\n",
       "      <td>eae2bd81fd19ec6093c645d90e92222e</td>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>2006-10-13 11:53:32</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>10</td>\n",
       "      <td>ATTEMPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single-KC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row Sample Name                    Transaction Id  \\\n",
       "0    1    All Data  13cb29890fa2be0ca31bcd07f35000d6   \n",
       "1    2    All Data  3fedf6c06ab6b9b3c36e245335445bcf   \n",
       "2    3    All Data  0f5bb1a5c133ac1aa0a3d32e4d44dde9   \n",
       "3    4    All Data  19a9aabf614d6f27dc9970dc842da081   \n",
       "4    5    All Data  eae2bd81fd19ec6093c645d90e92222e   \n",
       "\n",
       "                        Anon Student Id  Session Id                 Time  \\\n",
       "0  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580  2006-10-13 11:53:10   \n",
       "1  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580  2006-10-13 11:53:13   \n",
       "2  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580  2006-10-13 11:53:20   \n",
       "3  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580  2006-10-13 11:53:22   \n",
       "4  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580  2006-10-13 11:53:32   \n",
       "\n",
       "    Time Zone Duration (sec) Student Response Type  Student Response Subtype  \\\n",
       "0  US/Eastern             22               ATTEMPT                       NaN   \n",
       "1  US/Eastern              3          HINT_REQUEST                       NaN   \n",
       "2  US/Eastern              7          HINT_REQUEST                       NaN   \n",
       "3  US/Eastern              2          HINT_REQUEST                       NaN   \n",
       "4  US/Eastern             10               ATTEMPT                       NaN   \n",
       "\n",
       "   ... KC (MCAS5-State_WPI-Simple)  KC Category (MCAS5-State_WPI-Simple)  \\\n",
       "0  ...                         NaN                                   NaN   \n",
       "1  ...                         NaN                                   NaN   \n",
       "2  ...                         NaN                                   NaN   \n",
       "3  ...                         NaN                                   NaN   \n",
       "4  ...                         NaN                                   NaN   \n",
       "\n",
       "  KC (MCAS5-State_WPI-Simple).1  KC Category (MCAS5-State_WPI-Simple).1  \\\n",
       "0                           NaN                                     NaN   \n",
       "1                           NaN                                     NaN   \n",
       "2                           NaN                                     NaN   \n",
       "3                           NaN                                     NaN   \n",
       "4                           NaN                                     NaN   \n",
       "\n",
       "   KC (Single-KC) KC Category (Single-KC) KC (Unique-step)  \\\n",
       "0       Single-KC                     NaN              NaN   \n",
       "1       Single-KC                     NaN              NaN   \n",
       "2       Single-KC                     NaN              NaN   \n",
       "3       Single-KC                     NaN              NaN   \n",
       "4       Single-KC                     NaN              NaN   \n",
       "\n",
       "   KC Category (Unique-step)       School              Class  \n",
       "0                        NaN  ForestGrove  Period40607Dumphy  \n",
       "1                        NaN  ForestGrove  Period40607Dumphy  \n",
       "2                        NaN  ForestGrove  Period40607Dumphy  \n",
       "3                        NaN  ForestGrove  Period40607Dumphy  \n",
       "4                        NaN  ForestGrove  Period40607Dumphy  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20298da3-e39c-4ebc-b647-2a2f6d65c98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row                                          int64\n",
       "Sample Name                                 object\n",
       "Transaction Id                              object\n",
       "Anon Student Id                             object\n",
       "Session Id                                   int64\n",
       "Time                                        object\n",
       "Time Zone                                   object\n",
       "Duration (sec)                              object\n",
       "Student Response Type                       object\n",
       "Student Response Subtype                   float64\n",
       "Tutor Response Type                         object\n",
       "Tutor Response Subtype                     float64\n",
       "Level (Curriculum)                          object\n",
       "Problem Name                                 int64\n",
       "Problem View                               float64\n",
       "Problem Start Time                          object\n",
       "Step Name                                   object\n",
       "Attempt At Step                            float64\n",
       "Is Last Attempt                            float64\n",
       "Outcome                                     object\n",
       "Selection                                   object\n",
       "Action                                      object\n",
       "Input                                       object\n",
       "Feedback Text                               object\n",
       "Feedback Classification                     object\n",
       "Help Level                                 float64\n",
       "Total Num Hints                            float64\n",
       "KC (WPI-Apr-2005)                           object\n",
       "KC Category (WPI-Apr-2005)                 float64\n",
       "KC (WPI-Apr-2005).1                         object\n",
       "KC Category (WPI-Apr-2005).1               float64\n",
       "KC (WPI-Apr-2005).2                         object\n",
       "KC Category (WPI-Apr-2005).2               float64\n",
       "KC (WPI-Apr-2005).3                         object\n",
       "KC Category (WPI-Apr-2005).3               float64\n",
       "KC (WPI-Apr-2005).4                         object\n",
       "KC Category (WPI-Apr-2005).4               float64\n",
       "KC (WPI-Apr-2005).5                         object\n",
       "KC Category (WPI-Apr-2005).5               float64\n",
       "KC (MCAS39-State_WPI-Simple)                object\n",
       "KC Category (MCAS39-State_WPI-Simple)      float64\n",
       "KC (MCAS39-State_WPI-Simple).1              object\n",
       "KC Category (MCAS39-State_WPI-Simple).1    float64\n",
       "KC (MCAS39-State_WPI-Simple).2              object\n",
       "KC Category (MCAS39-State_WPI-Simple).2    float64\n",
       "KC (MCAS39-State_WPI-Simple).3              object\n",
       "KC Category (MCAS39-State_WPI-Simple).3    float64\n",
       "KC (MCAS5-State_WPI-Simple)                 object\n",
       "KC Category (MCAS5-State_WPI-Simple)       float64\n",
       "KC (MCAS5-State_WPI-Simple).1               object\n",
       "KC Category (MCAS5-State_WPI-Simple).1     float64\n",
       "KC (Single-KC)                              object\n",
       "KC Category (Single-KC)                    float64\n",
       "KC (Unique-step)                            object\n",
       "KC Category (Unique-step)                  float64\n",
       "School                                      object\n",
       "Class                                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a934748-bd05-4cff-9c3d-656abb8bf948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>Session Id</th>\n",
       "      <th>Student Response Subtype</th>\n",
       "      <th>Tutor Response Subtype</th>\n",
       "      <th>Problem Name</th>\n",
       "      <th>Problem View</th>\n",
       "      <th>Attempt At Step</th>\n",
       "      <th>Is Last Attempt</th>\n",
       "      <th>Help Level</th>\n",
       "      <th>Total Num Hints</th>\n",
       "      <th>...</th>\n",
       "      <th>KC Category (WPI-Apr-2005).4</th>\n",
       "      <th>KC Category (WPI-Apr-2005).5</th>\n",
       "      <th>KC Category (MCAS39-State_WPI-Simple)</th>\n",
       "      <th>KC Category (MCAS39-State_WPI-Simple).1</th>\n",
       "      <th>KC Category (MCAS39-State_WPI-Simple).2</th>\n",
       "      <th>KC Category (MCAS39-State_WPI-Simple).3</th>\n",
       "      <th>KC Category (MCAS5-State_WPI-Simple)</th>\n",
       "      <th>KC Category (MCAS5-State_WPI-Simple).1</th>\n",
       "      <th>KC Category (Single-KC)</th>\n",
       "      <th>KC Category (Unique-step)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.451003e+06</td>\n",
       "      <td>1.451003e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.451003e+06</td>\n",
       "      <td>1.450822e+06</td>\n",
       "      <td>1.448076e+06</td>\n",
       "      <td>1.448076e+06</td>\n",
       "      <td>394514.000000</td>\n",
       "      <td>303756.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.255020e+05</td>\n",
       "      <td>4.409396e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.609072e+03</td>\n",
       "      <td>1.281691e+00</td>\n",
       "      <td>2.341389e+00</td>\n",
       "      <td>4.472597e-01</td>\n",
       "      <td>2.010413</td>\n",
       "      <td>3.529932</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.188686e+05</td>\n",
       "      <td>2.780981e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.119680e+03</td>\n",
       "      <td>6.858265e-01</td>\n",
       "      <td>2.543439e+00</td>\n",
       "      <td>4.972108e-01</td>\n",
       "      <td>1.419201</td>\n",
       "      <td>1.298585</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.720000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.627515e+05</td>\n",
       "      <td>1.363892e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.149000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.255020e+05</td>\n",
       "      <td>5.450824e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.133000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.088252e+06</td>\n",
       "      <td>6.838668e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.562000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.451003e+06</td>\n",
       "      <td>8.167924e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.865100e+04</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Row    Session Id  Student Response Subtype  \\\n",
       "count  1.451003e+06  1.451003e+06                       0.0   \n",
       "mean   7.255020e+05  4.409396e+06                       NaN   \n",
       "std    4.188686e+05  2.780981e+06                       NaN   \n",
       "min    1.000000e+00  6.720000e+02                       NaN   \n",
       "25%    3.627515e+05  1.363892e+06                       NaN   \n",
       "50%    7.255020e+05  5.450824e+06                       NaN   \n",
       "75%    1.088252e+06  6.838668e+06                       NaN   \n",
       "max    1.451003e+06  8.167924e+06                       NaN   \n",
       "\n",
       "       Tutor Response Subtype  Problem Name  Problem View  Attempt At Step  \\\n",
       "count                     0.0  1.451003e+06  1.450822e+06     1.448076e+06   \n",
       "mean                      NaN  5.609072e+03  1.281691e+00     2.341389e+00   \n",
       "std                       NaN  5.119680e+03  6.858265e-01     2.543439e+00   \n",
       "min                       NaN  7.000000e+00  1.000000e+00     1.000000e+00   \n",
       "25%                       NaN  1.149000e+03  1.000000e+00     1.000000e+00   \n",
       "50%                       NaN  3.133000e+03  1.000000e+00     1.000000e+00   \n",
       "75%                       NaN  9.562000e+03  1.000000e+00     3.000000e+00   \n",
       "max                       NaN  1.865100e+04  2.400000e+01     1.200000e+02   \n",
       "\n",
       "       Is Last Attempt     Help Level  Total Num Hints  ...  \\\n",
       "count     1.448076e+06  394514.000000    303756.000000  ...   \n",
       "mean      4.472597e-01       2.010413         3.529932  ...   \n",
       "std       4.972108e-01       1.419201         1.298585  ...   \n",
       "min       0.000000e+00       1.000000         0.000000  ...   \n",
       "25%       0.000000e+00       1.000000         3.000000  ...   \n",
       "50%       0.000000e+00       2.000000         3.000000  ...   \n",
       "75%       1.000000e+00       3.000000         4.000000  ...   \n",
       "max       1.000000e+00      57.000000        47.000000  ...   \n",
       "\n",
       "       KC Category (WPI-Apr-2005).4  KC Category (WPI-Apr-2005).5  \\\n",
       "count                           0.0                           0.0   \n",
       "mean                            NaN                           NaN   \n",
       "std                             NaN                           NaN   \n",
       "min                             NaN                           NaN   \n",
       "25%                             NaN                           NaN   \n",
       "50%                             NaN                           NaN   \n",
       "75%                             NaN                           NaN   \n",
       "max                             NaN                           NaN   \n",
       "\n",
       "       KC Category (MCAS39-State_WPI-Simple)  \\\n",
       "count                                    0.0   \n",
       "mean                                     NaN   \n",
       "std                                      NaN   \n",
       "min                                      NaN   \n",
       "25%                                      NaN   \n",
       "50%                                      NaN   \n",
       "75%                                      NaN   \n",
       "max                                      NaN   \n",
       "\n",
       "       KC Category (MCAS39-State_WPI-Simple).1  \\\n",
       "count                                      0.0   \n",
       "mean                                       NaN   \n",
       "std                                        NaN   \n",
       "min                                        NaN   \n",
       "25%                                        NaN   \n",
       "50%                                        NaN   \n",
       "75%                                        NaN   \n",
       "max                                        NaN   \n",
       "\n",
       "       KC Category (MCAS39-State_WPI-Simple).2  \\\n",
       "count                                      0.0   \n",
       "mean                                       NaN   \n",
       "std                                        NaN   \n",
       "min                                        NaN   \n",
       "25%                                        NaN   \n",
       "50%                                        NaN   \n",
       "75%                                        NaN   \n",
       "max                                        NaN   \n",
       "\n",
       "       KC Category (MCAS39-State_WPI-Simple).3  \\\n",
       "count                                      0.0   \n",
       "mean                                       NaN   \n",
       "std                                        NaN   \n",
       "min                                        NaN   \n",
       "25%                                        NaN   \n",
       "50%                                        NaN   \n",
       "75%                                        NaN   \n",
       "max                                        NaN   \n",
       "\n",
       "       KC Category (MCAS5-State_WPI-Simple)  \\\n",
       "count                                   0.0   \n",
       "mean                                    NaN   \n",
       "std                                     NaN   \n",
       "min                                     NaN   \n",
       "25%                                     NaN   \n",
       "50%                                     NaN   \n",
       "75%                                     NaN   \n",
       "max                                     NaN   \n",
       "\n",
       "       KC Category (MCAS5-State_WPI-Simple).1  KC Category (Single-KC)  \\\n",
       "count                                     0.0                      0.0   \n",
       "mean                                      NaN                      NaN   \n",
       "std                                       NaN                      NaN   \n",
       "min                                       NaN                      NaN   \n",
       "25%                                       NaN                      NaN   \n",
       "50%                                       NaN                      NaN   \n",
       "75%                                       NaN                      NaN   \n",
       "max                                       NaN                      NaN   \n",
       "\n",
       "       KC Category (Unique-step)  \n",
       "count                        0.0  \n",
       "mean                         NaN  \n",
       "std                          NaN  \n",
       "min                          NaN  \n",
       "25%                          NaN  \n",
       "50%                          NaN  \n",
       "75%                          NaN  \n",
       "max                          NaN  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cbb081e-0ba7-458c-8636-dbd7266352d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row                                        1451003\n",
       "Sample Name                                      1\n",
       "Transaction Id                             1451003\n",
       "Anon Student Id                               5046\n",
       "Session Id                                  392886\n",
       "Time                                       1027591\n",
       "Time Zone                                        1\n",
       "Duration (sec)                                 641\n",
       "Student Response Type                            2\n",
       "Student Response Subtype                         0\n",
       "Tutor Response Type                              2\n",
       "Tutor Response Subtype                           0\n",
       "Level (Curriculum)                               1\n",
       "Problem Name                                  1798\n",
       "Problem View                                    17\n",
       "Problem Start Time                          347840\n",
       "Step Name                                     5834\n",
       "Attempt At Step                                120\n",
       "Is Last Attempt                                  2\n",
       "Outcome                                          3\n",
       "Selection                                     5828\n",
       "Action                                          12\n",
       "Input                                        28427\n",
       "Feedback Text                                11816\n",
       "Feedback Classification                          3\n",
       "Help Level                                      57\n",
       "Total Num Hints                                 48\n",
       "KC (WPI-Apr-2005)                               87\n",
       "KC Category (WPI-Apr-2005)                       0\n",
       "KC (WPI-Apr-2005).1                             47\n",
       "KC Category (WPI-Apr-2005).1                     0\n",
       "KC (WPI-Apr-2005).2                             15\n",
       "KC Category (WPI-Apr-2005).2                     0\n",
       "KC (WPI-Apr-2005).3                              2\n",
       "KC Category (WPI-Apr-2005).3                     0\n",
       "KC (WPI-Apr-2005).4                              1\n",
       "KC Category (WPI-Apr-2005).4                     0\n",
       "KC (WPI-Apr-2005).5                              1\n",
       "KC Category (WPI-Apr-2005).5                     0\n",
       "KC (MCAS39-State_WPI-Simple)                    30\n",
       "KC Category (MCAS39-State_WPI-Simple)            0\n",
       "KC (MCAS39-State_WPI-Simple).1                  20\n",
       "KC Category (MCAS39-State_WPI-Simple).1          0\n",
       "KC (MCAS39-State_WPI-Simple).2                   9\n",
       "KC Category (MCAS39-State_WPI-Simple).2          0\n",
       "KC (MCAS39-State_WPI-Simple).3                   2\n",
       "KC Category (MCAS39-State_WPI-Simple).3          0\n",
       "KC (MCAS5-State_WPI-Simple)                      5\n",
       "KC Category (MCAS5-State_WPI-Simple)             0\n",
       "KC (MCAS5-State_WPI-Simple).1                    1\n",
       "KC Category (MCAS5-State_WPI-Simple).1           0\n",
       "KC (Single-KC)                                   1\n",
       "KC Category (Single-KC)                          0\n",
       "KC (Unique-step)                               318\n",
       "KC Category (Unique-step)                        0\n",
       "School                                          24\n",
       "Class                                          262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c4be5-b44e-4ea3-800e-ffe86b625ab0",
   "metadata": {},
   "source": [
    "Each row of the dataset represents an interaction an user has with an intelligent tutoring system.\n",
    "\n",
    "The students are divided between schools and classes.\n",
    "\n",
    "As we can see there are some columns that probably will not be very useful for most of the analysis.\n",
    "\n",
    "Some columns contains no unique values, so they are candidate to be dropped. Other ones have an exclusive value per row, not contributing with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8abdc3-9eae-44d6-9eb6-60db98209997",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4292514-6701-4254-9eb4-1548bf7b9b9b",
   "metadata": {},
   "source": [
    "The criteria used to drop the columns were:\n",
    "- Columns with one or less unique values in it.\n",
    "- Columns with all rows with unique values.\n",
    "- KC columns (KCs are Knowledge Components, created using the system provided by DataShop system, where we got the data).\n",
    "- Columns with high quantity of unique values (probably they will overfit the machine learning model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "116ea082-daf7-4e24-85d5-3af5977d108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnecessary_columns(df):\n",
    "    \"\"\" Drop unnecessary columns from a dataframe to be used during the analysis\n",
    "    The criteria used to drop the columns are:\n",
    "        - 1 o less unique values per column;\n",
    "        - All rows containing unique values;\n",
    "        - Columns that represent the KC;\n",
    "        - Columns with a high quantity of unique values.\n",
    "        \n",
    "    Arguments:\n",
    "        - df (pandas DataFrame): The dataframe containing the columns to be dropped.\n",
    "        \n",
    "    Returns:\n",
    "        - df_cleaned (pandas DataFrame): A copy of the input dataframe with the columns dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_values = df.nunique()\n",
    "    \n",
    "    # Dropping the columns with 0 or 1 exclusive values\n",
    "    df_cleaned = df.loc[:, (unique_values > 1)]\n",
    "    \n",
    "    # Dropping the columns with an unique value per row\n",
    "    df_cleaned = df_cleaned.loc[:, (unique_values < df_cleaned.shape[0])]\n",
    "    \n",
    "    # Dropping the KC columns\n",
    "    df_cleaned = df_cleaned.loc[:, [col.find('KC (') < 0 for col in df_cleaned.columns]]\n",
    "    \n",
    "    # Dropping columns with high variability values\n",
    "    # At this part only the \"Time\" and \"Problem Start Time\" were dropped\n",
    "    # I will not drop the Session Id column because I want to use it at the Machine Learning code\n",
    "    columns_to_drop = [k for k,v in df_cleaned.nunique().items() if ((v / df_cleaned.shape[0]) > 0.2) and (k != 'Session Id')]\n",
    "    df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06583109-717c-411f-bc4b-e722ca1bb381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_data_types(df):\n",
    "    \"\"\" Adjust the data types of columns classified as object or float to float and integer respectively.\n",
    "        \n",
    "    Arguments:\n",
    "        - df (pandas DataFrame): The dataframe containing the columns to be adjusted.\n",
    "        \n",
    "    Returns:\n",
    "        - df_new (pandas DataFrame): A copy of the input dataframe with the columns' types adjusted.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Converting the \"Duration (sec)\" values from object to float\n",
    "    # It had to be converted to float because it has some decimal values at some rows\n",
    "    # We had to replace the dot (.) values to convert the values to float\n",
    "    df_new['Duration (sec)'] = df_new['Duration (sec)'].replace('.', '0', regex=False).astype('float64')\n",
    "\n",
    "    # Converting some float columns to int to reduce the range of allowed values in these columns\n",
    "    # They don't need to use decimal points for theirs values\n",
    "    # I had to use the Int64 type (Pandas integer) instead of int64 type (Numpy integer) because the existent NaN values that could not be converted\n",
    "    float_to_int_columns = ['Problem View', 'Attempt At Step', 'Is Last Attempt', 'Help Level', 'Total Num Hints']\n",
    "\n",
    "    df_new[float_to_int_columns] = df_new[float_to_int_columns].astype('Int64')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb1cc9b9-4e5c-43b2-add2-2e37762ad89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = drop_unnecessary_columns(df)\n",
    "df_cleaned = adjust_data_types(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6297570-1f96-48a5-9b71-5d885c49fe38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anon Student Id</th>\n",
       "      <th>Session Id</th>\n",
       "      <th>Duration (sec)</th>\n",
       "      <th>Student Response Type</th>\n",
       "      <th>Tutor Response Type</th>\n",
       "      <th>Problem Name</th>\n",
       "      <th>Problem View</th>\n",
       "      <th>Step Name</th>\n",
       "      <th>Attempt At Step</th>\n",
       "      <th>Is Last Attempt</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Selection</th>\n",
       "      <th>Action</th>\n",
       "      <th>Input</th>\n",
       "      <th>Feedback Text</th>\n",
       "      <th>Feedback Classification</th>\n",
       "      <th>Help Level</th>\n",
       "      <th>Total Num Hints</th>\n",
       "      <th>School</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>22.0</td>\n",
       "      <td>ATTEMPT</td>\n",
       "      <td>RESULT</td>\n",
       "      <td>10168</td>\n",
       "      <td>1</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>1</td>\n",
       "      <td>80/100</td>\n",
       "      <td>Don't forget to reduce your fraction.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>3.0</td>\n",
       "      <td>HINT_REQUEST</td>\n",
       "      <td>HINT_MSG</td>\n",
       "      <td>10168</td>\n",
       "      <td>1</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HINT</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There are 100 squares and 80 are colored purple.</td>\n",
       "      <td>HINT</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>7.0</td>\n",
       "      <td>HINT_REQUEST</td>\n",
       "      <td>HINT_MSG</td>\n",
       "      <td>10168</td>\n",
       "      <td>1</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>HINT</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80/100 squares are colored purple. Reduce this...</td>\n",
       "      <td>HINT</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HINT_REQUEST</td>\n",
       "      <td>HINT_MSG</td>\n",
       "      <td>10168</td>\n",
       "      <td>1</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>HINT</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80/100 = 8/10 = 4/5</td>\n",
       "      <td>HINT</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stu_000271be877ea1e7bf4f038c96cee5f9</td>\n",
       "      <td>5660580</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ATTEMPT</td>\n",
       "      <td>RESULT</td>\n",
       "      <td>10168</td>\n",
       "      <td>1</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>Step0:10168:There are 100 squares in the 10 by...</td>\n",
       "      <td>1</td>\n",
       "      <td>4/5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ForestGrove</td>\n",
       "      <td>Period40607Dumphy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Anon Student Id  Session Id  Duration (sec)  \\\n",
       "0  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580            22.0   \n",
       "1  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580             3.0   \n",
       "2  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580             7.0   \n",
       "3  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580             2.0   \n",
       "4  Stu_000271be877ea1e7bf4f038c96cee5f9     5660580            10.0   \n",
       "\n",
       "  Student Response Type Tutor Response Type  Problem Name  Problem View  \\\n",
       "0               ATTEMPT              RESULT         10168             1   \n",
       "1          HINT_REQUEST            HINT_MSG         10168             1   \n",
       "2          HINT_REQUEST            HINT_MSG         10168             1   \n",
       "3          HINT_REQUEST            HINT_MSG         10168             1   \n",
       "4               ATTEMPT              RESULT         10168             1   \n",
       "\n",
       "                                           Step Name  Attempt At Step  \\\n",
       "0  Step0:10168:There are 100 squares in the 10 by...                1   \n",
       "1  Step0:10168:There are 100 squares in the 10 by...                2   \n",
       "2  Step0:10168:There are 100 squares in the 10 by...                3   \n",
       "3  Step0:10168:There are 100 squares in the 10 by...                4   \n",
       "4  Step0:10168:There are 100 squares in the 10 by...                5   \n",
       "\n",
       "   Is Last Attempt    Outcome  \\\n",
       "0                0  INCORRECT   \n",
       "1                0       HINT   \n",
       "2                0       HINT   \n",
       "3                0       HINT   \n",
       "4                1    CORRECT   \n",
       "\n",
       "                                           Selection Action   Input  \\\n",
       "0  Step0:10168:There are 100 squares in the 10 by...      1  80/100   \n",
       "1  Step0:10168:There are 100 squares in the 10 by...      1     NaN   \n",
       "2  Step0:10168:There are 100 squares in the 10 by...      1     NaN   \n",
       "3  Step0:10168:There are 100 squares in the 10 by...      1     NaN   \n",
       "4  Step0:10168:There are 100 squares in the 10 by...      1     4/5   \n",
       "\n",
       "                                       Feedback Text Feedback Classification  \\\n",
       "0              Don't forget to reduce your fraction.                     NaN   \n",
       "1   There are 100 squares and 80 are colored purple.                    HINT   \n",
       "2  80/100 squares are colored purple. Reduce this...                    HINT   \n",
       "3                                80/100 = 8/10 = 4/5                    HINT   \n",
       "4                                                NaN                     NaN   \n",
       "\n",
       "   Help Level  Total Num Hints       School              Class  \n",
       "0        <NA>             <NA>  ForestGrove  Period40607Dumphy  \n",
       "1           1             <NA>  ForestGrove  Period40607Dumphy  \n",
       "2           2             <NA>  ForestGrove  Period40607Dumphy  \n",
       "3           3             <NA>  ForestGrove  Period40607Dumphy  \n",
       "4        <NA>             <NA>  ForestGrove  Period40607Dumphy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454fc64-b7ea-4155-af76-660da1de83b4",
   "metadata": {},
   "source": [
    "## Checking the differences between some columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5dfdb-43a3-413c-a27c-ec65bf4ecc55",
   "metadata": {},
   "source": [
    "Some columns apparently have similar values or similar information.\n",
    "\n",
    "Below we analyzed the differences between the *Step Name* and the *Selection* columns. Apparently they have the same values for each row, so it would be wiser to drop one of them. The only difference we found between then is that the *Step Name* column has aditional text at the end of it, probably because some misconfiguration of the input dataset.\n",
    "\n",
    "The other ones that have similar information are the *Help Level* and the *Total Num Hints* columns. But the *Total Num Hints* only stores the maximum value of the *Help Level* grouped by *Session*, *Problem Name* and *Step Name*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c2eabb-5db9-480f-8fda-e6312d6cec8d",
   "metadata": {},
   "source": [
    "**_Step Name_ and _Selection_ columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af085e8-cad4-40d0-9a21-7a2198a93aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test DataFrame with only the rows that have explicitly different values on which column\n",
    "df_test_step_selection = df_cleaned[df_cleaned['Step Name'] != df_cleaned['Selection']][['Step Name', 'Selection']]\n",
    "df_test_step_selection = df_test_step_selection.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc21545e-5768-46cd-83b8-0c36fa586f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values at index 0 without reduncing the length of the \"Step Name\" column.\n",
      "Step0:10168:There are 100 squares in the 10 by 10 grid above. What fraction of the squares are colored purple? (Make sure you reduce the fraction) 1\n",
      "Step0:10168:There are 100 squares in the 10 by 10 grid above. What fraction of the squares are colored purple? (Make sure you reduce the fraction)\n",
      "\n",
      "Values at index 0 reduncing the length of the \"Step Name\" column.\n",
      "Step0:10168:There are 100 squares in the 10 by 10 grid above. What fraction of the squares are colored purple? (Make sure you reduce the fraction)\n",
      "Step0:10168:There are 100 squares in the 10 by 10 grid above. What fraction of the squares are colored purple? (Make sure you reduce the fraction)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "print('Values at index {} without reduncing the length of the \"Step Name\" column.'.format(idx))\n",
    "print(df_test_step_selection['Step Name'][idx])\n",
    "print(df_test_step_selection['Selection'][idx])\n",
    "\n",
    "selection_len = len(df_test_step_selection['Selection'][idx])\n",
    "\n",
    "print()\n",
    "print('Values at index {} reduncing the length of the \"Step Name\" column.'.format(idx))\n",
    "print(df_test_step_selection['Step Name'][idx][:selection_len])\n",
    "print(df_test_step_selection['Selection'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba4509a6-af42-489e-aa10-a9e6bfb44a1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4554/3989186722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_step_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mselection_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_step_selection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Selection'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_step_selection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Step Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_diff = 0\n",
    "total_nan = 0\n",
    "\n",
    "for i in range(df_test_step_selection.shape[0]):\n",
    "    selection_len = len(df_test_step_selection['Selection'][i])\n",
    "    \n",
    "    step = df_test_step_selection['Step Name'][i]\n",
    "    \n",
    "    if type(step) == str:\n",
    "        step = step[:selection_len]\n",
    "    else:\n",
    "        total_nan += 1\n",
    "    \n",
    "    if step != df_test_step_selection['Selection'][i]:\n",
    "        total_diff += 1\n",
    "\n",
    "print('Calculated differences between columns when the length of the \"Step Name\" column is reduced to match the \"Selection\" column.')\n",
    "print('Total of different values: {}'.format(total_diff))\n",
    "print('Total of different values with at leat one NaN: {}'.format(total_nan))\n",
    "print('Total of different values without the NaNs: {}'.format(total_diff - total_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789f19f-46bc-40b2-8567-dc1ccd26f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_diff = (total_diff - total_nan) / df_cleaned.shape[0]\n",
    "\n",
    "print('There is only {:.4f}% of different values between the \"Step Name\" and the \"Selection\" columns.'.format(pct_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916f85a-2374-4648-9c56-e4d292f2957a",
   "metadata": {},
   "source": [
    "There are so few values that the differences are not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14eec91-bd4e-4b62-9696-fe7a8e2136a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(columns=['Selection'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4443a-3a83-46a9-b87f-b24223fa2f84",
   "metadata": {},
   "source": [
    "**_Help Level_ and _Total Num Hints_ columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec62b6-ccb8-46af-af8a-6ba25fdd53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting only the rows where the \"Total Num Hints\" column has some value\n",
    "df_test_hints = df_cleaned[df_cleaned['Total Num Hints'] >= 0]\n",
    "\n",
    "df_test_hints = df_test_hints[df_test_hints['Total Num Hints'] != df_test_hints['Help Level']]\n",
    "\n",
    "df_test_hints[['Session Id', 'Problem Name', 'Step Name', 'Outcome', 'Help Level', 'Total Num Hints']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3cac6e-f1a2-49fd-beaf-7eb4f595f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total of different values between columns: {}'.format(df_test_hints.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3ed48-0eb7-410b-8e01-3f4559adefd6",
   "metadata": {},
   "source": [
    "## Enhancing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52370865-9fca-4c12-9518-db65913790e6",
   "metadata": {},
   "source": [
    "At this part we tried to create some new columns to be used during the training of the predictive model.\n",
    "\n",
    "Columns created:\n",
    "- Last Help Level: indicating what was the last value of the column *Help Level* before CORRECT or INCORRECT value at the *Outcome* column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81846b-5003-4219-8d68-4d8b688a060e",
   "metadata": {},
   "source": [
    "**Last Help Level**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045cc99-42c6-4d9c-a004-05064271cf93",
   "metadata": {},
   "source": [
    "We can get the Last Help Level grouping the *Session Id*, *Problem Name* and *Step Name* columns.\n",
    "\n",
    "We have to group by these columns because after that, the Help Level returns to the value of 0.\n",
    "\n",
    "We have to fill the remaing NaN values with 0 because, sometimes the grouping doesn't start with the outcoume of a HINT, causing the Help Value to be a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790fd1b-00dc-4647-805b-9d6952c5a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://stackoverflow.com/questions/44111425/cannot-use-fillna-when-a-condition-is-introduced\n",
    "\n",
    "# This step could take a while\n",
    "group_columns = ['Session Id', 'Problem Name', 'Step Name']\n",
    "\n",
    "# Filling the next value based on the grouping\n",
    "df_cleaned['Last Help Level'] = df_cleaned.groupby(group_columns)['Help Level'].fillna(method='ffill')\n",
    "\n",
    "# Filling the initial value\n",
    "df_cleaned['Last Help Level'] = df_cleaned['Last Help Level'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c33f1-611e-4b2d-adb9-5e88a5657fbb",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0355f4-7b14-484a-a039-7f29ee788bf2",
   "metadata": {},
   "source": [
    "Here we tried to identify some patterns in our data to see if we could make some assumptions about the data or if it could generate some trouble when used as input to the machine learning algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cb267-f6d8-49ec-ab0b-8220566d2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(data, title='Number of occurrences', xlabel='x', ylabel='Number of occurrences', rotation=90, show_xticks=True):\n",
    "    \"\"\"Plots a bar chart with some customizations\n",
    "    \n",
    "    Arguments:\n",
    "        - data (pandas Series): A series containing the data to plot the chart\n",
    "        - title (str): The title of the chart\n",
    "        - xlabel (str): The label of the x axis of the chart\n",
    "        - ylabel (str): The label of the y axis of the chart\n",
    "        - rotation (int): The rotation angle of the values of the x axis\n",
    "        - show_xticks (boolean): Definie if the chart has to show or not the values at xticks\n",
    "    \n",
    "    Returns:\n",
    "        - None: Only plots the bar chart\n",
    "    \"\"\"\n",
    "    \n",
    "    x = data.keys()\n",
    "    y = data.values\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.bar(x, y);\n",
    "    \n",
    "    plt.title(title);\n",
    "    plt.xlabel(xlabel);\n",
    "    plt.ylabel(ylabel);\n",
    "    plt.xticks(rotation=rotation);\n",
    "    \n",
    "    if not show_xticks:\n",
    "        plt.xticks([])\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65511f7-2ff3-4b60-90cc-ca67326b96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(data):\n",
    "    \"\"\" Print some statistics based on the input data\n",
    "        The printed statistics are:\n",
    "            - The number of distinct values;\n",
    "            - The mean;\n",
    "            - The median;\n",
    "            - The standard deviation.\n",
    "    \n",
    "    Arguments:\n",
    "        - data (pandas Series): A series containing the data to plot the chart\n",
    "        \n",
    "    Returns:\n",
    "        - None: Only print the statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Number of distinct values: {}'.format(len(data)))\n",
    "    print('Mean: {:.2f}'.format(data.mean()))\n",
    "    print('Median: {:.2f}'.format(data.median()))\n",
    "    print('Standard Deviation: {:.2f}'.format(data.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990dd25a-9ced-4767-9d6b-d8c3605a53fb",
   "metadata": {},
   "source": [
    "## Analyzing the number of interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed042147-c5af-4e1c-b132-e799351603f0",
   "metadata": {},
   "source": [
    "**By School**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec038add-4f6e-4bcc-8933-14708408af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'School'\n",
    "data = df_cleaned[column].value_counts()\n",
    "plot_bar(data, title='Number of interactions by {}'.format(column), xlabel=column)\n",
    "\n",
    "print_statistics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663dcefa-f1eb-4623-8ac1-2a2779ecd461",
   "metadata": {},
   "source": [
    "**By Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7663bc7-3dd8-4d10-b3ab-0111dc81a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Class'\n",
    "data = df_cleaned[column].value_counts()\n",
    "\n",
    "# Hide the xticks because there is a lot of distinct values to show and the importance of this char is to show the distribution not the values by itself\n",
    "plot_bar(data, title='Number of interactions by {}'.format(column), xlabel=column, show_xticks=False)\n",
    "\n",
    "print_statistics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552aa752-8f92-4ee2-bf09-ae944c415053",
   "metadata": {},
   "source": [
    "**By Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa94e5e-252b-48c3-b8af-9655bc9e4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Student'\n",
    "data = df_cleaned['Anon ' + column + ' Id'].value_counts()\n",
    "\n",
    "# Hide the xticks because there is a lot of distinct values to show and the importance of this char is to show the distribution not the values by itself\n",
    "plot_bar(data, title='Number of interactions by {}'.format(column), xlabel=column, show_xticks=False)\n",
    "\n",
    "print_statistics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f095d9-d83f-439e-80e2-289c6251a22f",
   "metadata": {},
   "source": [
    "As we can see the number of interactions is not well distribuited, mostly comparing the distribution between schools where the ForestGrove school has a higher number of interactions. This could cause some bias at these analyses.\n",
    "\n",
    "The interactions divided between classes and students follow the same pattern but with a lower standard deviation on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f8ddb-c7f9-4589-a628-7ee3f94b9f61",
   "metadata": {},
   "source": [
    "## Analyzing the number of students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80a830-9925-497d-9e14-b0b0d5b43cef",
   "metadata": {},
   "source": [
    "**By School**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1be5f7-97a2-46ad-b5c5-757d086cf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://www.kite.com/python/answers/how-to-count-unique-values-in-a-pandas-dataframe-group-in-python\n",
    "\n",
    "grouped_df = df_cleaned[['Anon Student Id', 'School']].groupby('School')\n",
    "grouped_df = grouped_df.agg({'Anon Student Id': 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc4a81-861f-4e3c-b49e-669882f631b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(grouped_df['Anon Student Id'].tolist(), index=grouped_df['School']).sort_values(ascending=False)\n",
    "plot_bar(data, title='Number of students by school', xlabel='School')\n",
    "\n",
    "print_statistics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343370fb-db2a-445f-88d5-c5ab8e191d18",
   "metadata": {},
   "source": [
    "**Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757f492-f9d8-450a-ad92-10ce269ce7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df_cleaned[['Anon Student Id', 'School', 'Class']].groupby(['School', 'Class'])\n",
    "grouped_df = grouped_df.agg({'Anon Student Id': 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01432bbc-b252-483c-89b8-c083837b4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = grouped_df['Anon Student Id']\n",
    "plot_bar(data, title='Number of students by school and class', xlabel='School + Class', show_xticks=False)\n",
    "\n",
    "print_statistics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a004ee-f2eb-4b43-a326-6b7561ab98fb",
   "metadata": {},
   "source": [
    "The distribution of students between schools follow the same structure of the number of interactions, with a higher standard deviation and a big difference between the values of mean and median.\n",
    "\n",
    "The number of students per class is well distributed with a few outiliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864839b-ffb3-419b-8433-2b9acb9361ba",
   "metadata": {},
   "source": [
    "# Predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1e6af-5451-4ee2-a810-63d8755f1ba4",
   "metadata": {},
   "source": [
    "At this part we tried to create a model that show us the best way to use the tutoring system to get the most of it.\n",
    "\n",
    "We tried to predict when the students have a higher probability to input a right answer after receiving some hints.\n",
    "\n",
    "The algorithms used were:\n",
    "- MultinomialNB, as the baseline model to compare with the others;\n",
    "- KNeighborsClassifier;\n",
    "- DecisionTreeClassifier;\n",
    "- GaussianNB;\n",
    "- XGBClassifier;\n",
    "\n",
    "We tried to use the SVC alogorithm but it was too slow to train so we discarded its use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df02cb-62d5-4895-9fc5-2673b3daa427",
   "metadata": {},
   "source": [
    "## Defining the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df351ad9-b989-4616-85f7-e5f1c6962b35",
   "metadata": {},
   "source": [
    "The choosed metrics to evaluate the models were:\n",
    "- AUC (Area Under the Curve);\n",
    "- F1-score;\n",
    "- Accuracy;\n",
    "- Fit time (how much time the algorithm spent fitting with the training data).\n",
    "\n",
    "The AUC was defined as the main metric to be used. Its choice was based upon the fact that the AUC could generate a single number to determine how good a model is performing based on a variety of thresholds of the predicted probabilities of the classes.\n",
    "\n",
    "F1-score was a metric used to analyze how well the generated model is going to run with a fixed threshold. It is based on the harmonic mean between the precision and recall metrics.\n",
    "\n",
    "Accuracy and fit time were choosed as baseline metrics to help exclude some bad algorithms, so a algorithm with a low accuracy or a slow fit time could be a reason to discard the use of this algorithm.\n",
    "\n",
    "If you want to understand these metrics better you could read this article: [Classification & Regression Evaluation Metrics](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c839b-8f88-4060-9353-797c25fa033c",
   "metadata": {},
   "source": [
    "## Preparing the dataset for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4e822-c5c6-44f0-929a-6b2d6c301d7f",
   "metadata": {},
   "source": [
    "Here we made some changes at the data to become an input to the machine learning models.\n",
    "\n",
    "Only the CORRECT and INCORRECT outputs were considered at this analysis, because we considered that the HINT output could be considered as as intermediate level and its values were already used by the *Last Help Level* column.\n",
    "\n",
    "We created a sample of the data to be easier to work with it and to have a less resource consumption.\n",
    "\n",
    "Some functions were defined here to make the code more reusable on the next sections of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b584617-ecce-4c2c-92fa-fedd2110116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_columns = ['Problem Name', 'Step Name', 'Attempt At Step', 'Outcome', 'Last Help Level']\n",
    "\n",
    "def generate_samples(ml_columns, df_cleaned=df_cleaned):\n",
    "    \"\"\" Generate sample data based on the default dataframe and \n",
    "    the columns defined in the parameters.\n",
    "    \n",
    "    The dataframe is filtered to get only the CORRECT and INCORRECT outcomes.\n",
    "    \n",
    "    The generated sample uses the bootstrapping effect.\n",
    "    \n",
    "    Arguments:\n",
    "        - ml_columns (list): A list containing the columns to be retrieved from the dataset\n",
    "        - df_cleaned (pandas DataFrame): The defult dataframe to be filtered and sampled\n",
    "        \n",
    "    Returns:\n",
    "        - df_ml (pandas DataFrame): The sample dataframe\n",
    "        - df_filtered (pandas DataFrame): The dataframe with all rows of the original but only\n",
    "            with the CORRECT and INCORRECT outcomes and the inputted columns\n",
    "    \"\"\"\n",
    "\n",
    "    df_filtered = df_cleaned[df_cleaned['Outcome'].isin(['CORRECT', 'INCORRECT'])][ml_columns]\n",
    "\n",
    "    df_ml = df_filtered.sample(n=N_SAMPLES, replace=True, ignore_index=True, random_state=SEED)\n",
    "    \n",
    "    return df_ml, df_filtered\n",
    "\n",
    "df_ml, df_filtered = generate_samples(ml_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fed46-2098-4e56-b861-d79af1f28444",
   "metadata": {},
   "source": [
    "To generate the samples we used the parameter *replace=True* to get a bootstrapping effect from our data.\n",
    "\n",
    "If you like to understand more you could read the Wikipedia page: [Bootstrapping_(statistics)](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34382612-0766-4620-9c2a-bd519b7d8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['Outcome'].value_counts() / df_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d933c00-e07f-40ca-accb-5ae6a500cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['Outcome'].value_counts() / df_ml.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3a8aa-dc3f-4546-95de-adb4e0c2a1f6",
   "metadata": {},
   "source": [
    "The dristribution of the outputs is similar between the sample and the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc614e6-907c-4d13-8789-f909004b9803",
   "metadata": {},
   "source": [
    "### Managing NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395e4df-2aa3-4d65-8ac6-0eaa390d82ce",
   "metadata": {},
   "source": [
    "As we can see below ther isn't any NaN values at the filtered dataframe created to generate the sample data, so we can conclude that each sample is going to have zero NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176cf46-7cee-4ef5-b917-e0103be8a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec3ef1-b0e8-4454-a4c3-c0ec6253a492",
   "metadata": {},
   "source": [
    "### Creating dummy columns for the *Step Name* column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12667b53-9212-45eb-9fd9-a88f9cd5cc77",
   "metadata": {},
   "source": [
    "We had to create new columns for the categorical values of the *Step Name* column to pass the data to the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e123a-3c83-47bc-9a05-033775c37adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_step_dummies(df):\n",
    "    \"\"\" Create dummy columns from the categorical values of the Step Name column \n",
    "    to be used by the machine learning models.\n",
    "    \n",
    "    The Step Name column is also dropped, because it's not more necessary.\n",
    "    \n",
    "    Arguments:\n",
    "        - df (pandas DataFrame): The dataframe that contains the Step Name column\n",
    "        \n",
    "    Returns:\n",
    "        - df_ml (pandas DataFrame): The dataframe with the new columns and without the categorical values\n",
    "    \"\"\"\n",
    "    \n",
    "    df_ml = df.copy()\n",
    "\n",
    "    # This step is to get smaller names for the generated columns\n",
    "    steps_names = df_ml['Step Name'].unique()\n",
    "\n",
    "    dummy_columns_names = []\n",
    "\n",
    "    # Created this variable to get only unique column names \n",
    "    i = 0\n",
    "\n",
    "    for step_name in steps_names:\n",
    "        idx = step_name.index(':', 7)\n",
    "        dummy_columns_names.append(step_name[:idx] + '_' + str(i))\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    step_dummies = pd.get_dummies(df_ml['Step Name'])\n",
    "    step_dummies.columns = dummy_columns_names\n",
    "    \n",
    "    \n",
    "    df_ml = pd.concat([df_ml, step_dummies], axis=1)\n",
    "    df_ml = df_ml.drop('Step Name', axis=1)\n",
    "    \n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489a947-4535-437d-8320-9ba3ac27fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = create_step_dummies(df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b78e4e-5580-4527-84c5-59bb66e0019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa7e88-e17d-4c75-8371-d3c962a0c5ff",
   "metadata": {},
   "source": [
    "As you can see, now we have many more columns to input to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d94b4a-98ac-4fc2-b07f-b9743613ba17",
   "metadata": {},
   "source": [
    "### Changing some data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8861851-ae1f-4e81-9538-d363bf286b14",
   "metadata": {},
   "source": [
    "Some machine learning models don't work well while using some data types like Int64 (pandas integer), so we had to change these types so the data could be used more universally between all the models.\n",
    "\n",
    "We did too encode the column output, replacing the string values to integers to be equally used by the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f6e0d-5443-4abd-ba2e-caeea0fe6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dtypes(df):\n",
    "    \"\"\" Change the data types of the Last Help Level and Attempt At Step columns to int64\n",
    "    so that they could be more universally used by the machine learning models.\n",
    "    \n",
    "    The values from the Outcome column are encoded with 1 representing the CORRECT values\n",
    "    and 0 representing the INCORRECT values.\n",
    "    \n",
    "    Arguments:\n",
    "        - df (pandas DataFrame): The dataframe that contains the columns to have the data type changed\n",
    "            and the Outcome column to be encoded\n",
    "        \n",
    "    Returns:\n",
    "        - df_ml (pandas DataFrame): The dataframe with the new data types and the encoded Outcome column\n",
    "    \"\"\"\n",
    "    \n",
    "    df_ml = df.copy()\n",
    "\n",
    "    df_ml['Last Help Level'] = df_ml['Last Help Level'].astype('int64')\n",
    "    df_ml['Attempt At Step'] = df_ml['Attempt At Step'].astype('int64')\n",
    "    \n",
    "    df_ml['Outcome'] = df_ml['Outcome'].replace({'CORRECT': 1, 'INCORRECT': 0})\n",
    "    \n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45361c-6031-4f5a-9811-2a95727ab310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = replace_dtypes(df_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439093fb-a82b-4aa7-8c60-3184f82963d7",
   "metadata": {},
   "source": [
    "### Create train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e573d24-4494-4716-845d-986b662a705c",
   "metadata": {},
   "source": [
    "The labels we tried to predict come from the Outcome columns. The other columns from the dataframe were used as inputs to the machine learning algorithms.\n",
    "\n",
    "Here we used the train_test_split function from the sklearn package to create the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53a59a-8448-4bc6-9711-f7e81bcced56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_create(df_ml):\n",
    "    \"\"\" Get the X and Y to be used to train the machine learning models and to test the models\n",
    "    with an unseen data.\n",
    "    \n",
    "    The Y values are based on the Outcome column. The other columns compose the X dataframe.\n",
    "    \n",
    "    Arguments:\n",
    "        - df_ml (pandas DataFrame): The dataframe that contains the data to be used by \n",
    "            the machine learning algorithms\n",
    "        \n",
    "    Returns:\n",
    "        - X_train (pandas DataFrame): The input dataframe to be used to train the machine learning models\n",
    "        - X_test (pandas DataFrame): The input dataframe to be used to test the machine learning models\n",
    "        - y_train (pandas Series): The output values to be predicted by the machine learning models during training\n",
    "        - y_test (pandas Series): The output values to be predicted by the machine learning models during testing\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df_ml.drop('Outcome', axis=1)\n",
    "    y = df_ml['Outcome']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394365f-a4b6-49b7-b3df-c9c92642f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_create(df_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db4911-1e90-4010-b807-a74fcfb9a0a2",
   "metadata": {},
   "source": [
    "## Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d664b-7fa3-4d45-a776-67d611cbd211",
   "metadata": {},
   "source": [
    "Here we started to work with the machine learning algorithms.\n",
    "\n",
    "Some helper functions were created to make it easier to rerun the code without having to replicate the code.\n",
    "\n",
    "During the process, metrics were collect to help to determine a good model to be used during the predictions.\n",
    "\n",
    "We started creating a baseline model to help with the comparisons between model, after that the other algorithms were tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13283d9-5ed0-454f-abf9-834419e3dbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a dictionary to store the models' metrics\n",
    "model_metrics = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdba7f1-ad5e-4105-83db-ab4bd61feb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_pred_prob):\n",
    "    \"\"\" Get important metrics based on the parameters values and put then\n",
    "    inside a python dictionary.\n",
    "    \n",
    "    The returned metrics are:\n",
    "        - accuracy;\n",
    "        - roc-auc;\n",
    "        - f1-score.\n",
    "    \n",
    "    Arguments:\n",
    "        - y_test (list): The list containing the true labels' values of the test dataset\n",
    "        - y_pred (list): The list containing the predicted labels' values of the test dataset\n",
    "        - y_pred_prob (list): The list containing the predicted labels' probabilities of the test dataset\n",
    "        \n",
    "    Returns:\n",
    "        - metrics (dict): A dictionary containing the name of the metrics and the respective values\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = dict()\n",
    "    \n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    metrics['accuracy'] = '{:.2f}%'.format(cr['accuracy'] * 100)\n",
    "    metrics['roc-auc'] = '{:.2f}%'.format(roc_auc_score(y_test, y_pred_prob[:, 1]) * 100)\n",
    "    metrics['f1-score'] = '{:.2f}%'.format(cr['macro avg']['f1-score'] * 100)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c2613-6f9b-4a13-b642-f23263b4207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://towardsdatascience.com/simple-little-tables-with-matplotlib-9780ef5d0bc4\n",
    "\n",
    "def plot_table(data=model_metrics, title='Models Comparison'):\n",
    "    \"\"\" Plot a prettier table using matplotlib to help to compare the metrics generated\n",
    "    by the machine learning algorithms.\n",
    "    \n",
    "    Arguments:\n",
    "        - data (dict): A dictionary containing the name of the machine learning model\n",
    "        and the metrics generated by it\n",
    "            The structure of the expected data is like:\n",
    "                { 'model_name': {\n",
    "                                    'metric_1': value,\n",
    "                                    'metric_2': value\n",
    "                                }\n",
    "                }\n",
    "        - title (str): The titled to be printed upside the table\n",
    "        \n",
    "    Returns:\n",
    "        - None: Only plots the table with the title and the imputed metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    cell_text = []\n",
    "    col_labels = []\n",
    "    row_labels = []\n",
    "    \n",
    "    row_name_padding = ' '*20\n",
    "\n",
    "    # Fill the arrays for the table\n",
    "    for model_name in data.keys():\n",
    "        row_labels.append(row_name_padding + model_name + row_name_padding)\n",
    "\n",
    "        if len(col_labels) == 0:\n",
    "            for col_name in data[model_name].keys():\n",
    "                col_labels.append(col_name)\n",
    "\n",
    "        values = []\n",
    "        for value in data[model_name].values():\n",
    "            values.append(value)\n",
    "\n",
    "        cell_text.append(values)\n",
    "\n",
    "    # Setting some default colors\n",
    "    fig_background_color = 'skyblue'\n",
    "    fig_border = 'steelblue'\n",
    "\n",
    "    # Get some lists of color specs for row and column headers\n",
    "    rcolors = plt.cm.BuPu(np.full(len(row_labels), 0.1))\n",
    "    ccolors = plt.cm.BuPu(np.full(len(col_labels), 0.1))\n",
    "\n",
    "    # Create the figure. Setting a small pad on tight_layout\n",
    "    # seems to better regulate white space. Sometimes experimenting\n",
    "    # with an explicit figsize here can produce better outcome.\n",
    "    plt.figure(linewidth=2,\n",
    "               edgecolor=fig_border,\n",
    "               facecolor=fig_background_color,\n",
    "               tight_layout={'pad':1},\n",
    "               figsize=(16,3))\n",
    "\n",
    "    # Add a table at the bottom of the axes\n",
    "    tb = plt.table(cellText=cell_text,\n",
    "                   cellLoc='center',\n",
    "                   rowLabels=row_labels,\n",
    "                   rowColours=rcolors,\n",
    "                   rowLoc='center',\n",
    "                   colColours=ccolors,\n",
    "                   colLabels=col_labels,\n",
    "                   loc='center')\n",
    "\n",
    "\n",
    "    # Scaling is the only influence we have over top and bottom cell padding.\n",
    "    # Make the rows taller (i.e., make cell y scale larger).\n",
    "    tb.scale(1, 2.5)\n",
    "\n",
    "    # Hide axes\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Hide axes border\n",
    "    plt.box(on=None)\n",
    "\n",
    "    # Add title\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8bc0f-7bfc-4b8d-9674-1a0fe53711f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(y_pred, model_name='', metrics={}, y_test=y_test):\n",
    "    \"\"\" Plot a confusion matrix to be a reference on how the machine learning model\n",
    "    is predicting the labels.\n",
    "    \n",
    "    It also prints the metrics generated by the model.\n",
    "    \n",
    "    Arguments:\n",
    "        - y_pred (list): A list containing the predicted labels\n",
    "        - model_name (str): A text to be printed to identify the machine learning model\n",
    "        - metrics (dict): A dictionary containing the metrics names and values\n",
    "        - y_test (pandas Series): The expected output values to be compared with the predicted values\n",
    "        \n",
    "    Returns:\n",
    "        - None: Only plots the confusion matrix and prints the metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    labels = ['INCORRECT', 'CORRECT']\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=labels, cmap='BuPu', colorbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show();\n",
    "    \n",
    "    print('Model metrics:')\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd6337-38f8-4f6c-9ce2-19167424d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_process(clf, model_name,  X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, model_metrics=model_metrics, threshold=0.5):\n",
    "    \"\"\" Runs a pipeline that trains the machine learning model, calculate some metrics\n",
    "    and plot the model performance for comparison between them.\n",
    "    \n",
    "    Arguments:\n",
    "        - clf (Machine Learning classifier): The classifier to be trained and to be used to make predictions\n",
    "        - model_name (str): The name of the model to be used to fill the metrics dictionary \n",
    "            and to print while showing the results\n",
    "        - X_train (pandas DataFrame): The input dataframe to be used to train the machine learning models\n",
    "        - X_test (pandas DataFrame): The input dataframe to be used to test the machine learning models\n",
    "        - y_train (pandas Series): The output values to be predicted by the machine learning models during training\n",
    "        - y_test (pandas Series): The output values to be predicted by the machine learning models during testing\n",
    "        - model_metrics (dict): The dictionary containing the metrics of the trained models\n",
    "        - threshold (float): A value between 0 and 1 to indicate the threshold of the prediction probability\n",
    "            of the true class\n",
    "        \n",
    "    Returns:\n",
    "        - clf (Machine Learning classifier): The classifier that had been trained\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Had to do this because of the annoying warnings of the model\n",
    "    if model_name == 'KNN':\n",
    "        clf.fit(X_train.values, y_train)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    fit_time = round(time.time() - start_time, 2)\n",
    "\n",
    "    # Had to do this because of the annoying warnings of the model\n",
    "    if model_name == 'KNN':\n",
    "        y_pred = clf.predict(X_test.values)\n",
    "        y_pred_prob = clf.predict_proba(X_test.values)\n",
    "    else:\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred_prob = clf.predict_proba(X_test)\n",
    "        \n",
    "    if threshold != 0.5:\n",
    "        y_pred = (y_pred_prob[:, 1] >= threshold).astype('int')\n",
    "\n",
    "    metrics = get_metrics(y_test, y_pred, y_pred_prob)\n",
    "    metrics['fit_time'] = fit_time\n",
    "\n",
    "    model_metrics[model_name] = metrics\n",
    "\n",
    "    plot_model_performance(y_pred, model_name=model_name, metrics=metrics)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e933f-7190-4777-b064-25807ee85da4",
   "metadata": {},
   "source": [
    "### The baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654282f-51b2-457c-a211-11f014931514",
   "metadata": {},
   "source": [
    "At this part we started creating a baseline model to get some metrics to compare to other machine learning algorithms.\n",
    "\n",
    "The Multinomial Naive Bayes was selected to be the baseline model because it is fast and has few parameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df056349-b948-4ece-976a-ae6381a30140",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(MultinomialNB(), 'Multinomial NB');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545f07e-d878-430e-a757-e418a98a4aa3",
   "metadata": {},
   "source": [
    "### Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9c0f-27e7-49d6-bda0-ce42a789c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d\n",
    "# https://www.kaggle.com/dansbecker/xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8992f-4d8e-4a5f-a7c9-f4bf309ee475",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(KNeighborsClassifier(n_jobs=-1), 'KNN');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb7fab-109d-48f9-aca3-eca38655d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(DecisionTreeClassifier(), 'Decision Tree');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373ec58-7a55-4f8e-8286-0e530a96a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a lot of time to execute ;(\n",
    "# With the sample size of 10 thousand values it took more than 6 minutes to train\n",
    "# Because of this we didn't continue using it\n",
    "# from sklearn.svm import SVC\n",
    "# model_process(SVC(probability=True), 'SVC');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3ffb5-4a29-4499-a63e-9f6345cd28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(GaussianNB(), 'Gaussian NB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de87df-fd8e-4ea2-92ee-25770f59edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(XGBClassifier(use_label_encoder=False), 'XGBoost');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c163f-22ee-4415-b8d0-df6677b197ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352f85f-0bd9-42fe-b1d7-641f4083bb9d",
   "metadata": {},
   "source": [
    "## Optimizing some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173af75-89c1-4cdd-ab44-e76e35279478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aiinpractice.com/xgboost-hyperparameter-tuning-with-bayesian-optimization/\n",
    "# https://github.com/fmfn/BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66340adc-8e14-47cd-8c11-fd63eec5b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_defaults(param_grid={}):\n",
    "    \"\"\" Get the default values of the model and parameters to be used while optimizing \n",
    "    the KNN model.\n",
    "    \n",
    "    Arguments:\n",
    "        - param_grid (dict): a dictionary to be used instead of the default dictionary\n",
    "            containing the name of the parameters and possible values\n",
    "        \n",
    "    Returns:\n",
    "        - KNeighborsClassifier (KNeighborsClassifier): The instance of the machine learning\n",
    "            classifier\n",
    "        - param_grid (dict): The dictionary with the parameters used during the optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    if param_grid == {}:\n",
    "        param_grid = {\n",
    "            'n_neighbors': list(range(1, 11)),\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "        \n",
    "    return KNeighborsClassifier(n_jobs=-1), param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494c0d7-e240-4f0c-a12e-5a4b48b27cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_defaults(param_grid={}):\n",
    "    \"\"\" Get the default values of the model and parameters to be used while optimizing \n",
    "    the Decision Tree model.\n",
    "    \n",
    "    Arguments:\n",
    "        - param_grid (dict): a dictionary to be used instead of the default dictionary\n",
    "            containing the name of the parameters and possible values\n",
    "        \n",
    "    Returns:\n",
    "        - DecisionTreeClassifier (DecisionTreeClassifier): The instance of the machine learning\n",
    "            classifier\n",
    "        - param_grid (dict): The dictionary with the parameters used during the optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    if param_grid == {}:\n",
    "        param_grid = {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [1, 10, 25, 50, 100, None],\n",
    "            'min_samples_split': [2, 3, 5, 7, 10],\n",
    "            'max_features': [None, 'sqrt', 'log2']\n",
    "        }\n",
    "        \n",
    "    return DecisionTreeClassifier(), param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d056dc-2cc9-4c82-ac88-cc9484633d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_nb_defaults(param_grid={}):\n",
    "    \"\"\" Get the default values of the model and parameters to be used while optimizing \n",
    "    the Gaussian Naive Bayes model.\n",
    "    \n",
    "    Arguments:\n",
    "        - param_grid (dict): a dictionary to be used instead of the default dictionary\n",
    "            containing the name of the parameters and possible values\n",
    "        \n",
    "    Returns:\n",
    "        - GaussianNB (GaussianNB): The instance of the machine learning classifier\n",
    "        - param_grid (dict): The dictionary with the parameters used during the optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    if param_grid == {}:\n",
    "        param_grid = {\n",
    "            'var_smoothing': np.logspace(0,-9, num=50)\n",
    "        }\n",
    "        \n",
    "    return GaussianNB(), param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d1ec7-b0b2-4227-b4b5-3ee394c07b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_with_grid_search(model_name, param_grid={}, scoring='roc_auc', cv=3, n_jobs=N_JOBS,\n",
    "                             X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    \"\"\" Helper function used to optimize some machine learning models using the GridSearchCV\n",
    "    class and a dictionary with the optimization parameters.\n",
    "    \n",
    "    Arguments:\n",
    "        - model_name (str): The name of the model to be used to get the right machine learning model,\n",
    "            get the right parameters to be optimized and print the results\n",
    "            The acceptables model names are: KNN, Decision Tree and Gaussian NB\n",
    "        - param_grid (dict): The dictionary with the parameters to be used during the optimization \n",
    "        - scoring (str): The metric to be used to evaluate the models\n",
    "            A complete list of the metrics could be found at: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "        - cv (int): Determine the number of folds of the cross validation\n",
    "        - n_jobs (int): The number of jobs to run in parallel. -1 means all processors available\n",
    "        - X_train (pandas DataFrame): The input dataframe to be used to train the machine learning models\n",
    "        - X_test (pandas DataFrame): The input dataframe to be used to test the machine learning models\n",
    "        - y_train (pandas Series): The output values to be predicted by the machine learning models during training\n",
    "        - y_test (pandas Series): The output values to be predicted by the machine learning models during testing\n",
    "        - model_metrics (dict): The dictionary containing the metrics of the trained models\n",
    "        - threshold (float): A value between 0 and 1 to indicate the threshold of the prediction probability\n",
    "            of the true class\n",
    "        \n",
    "    Returns:\n",
    "        - clf (Machine Learning classifier): The classifier with the best parameter values based on the inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name == 'KNN':\n",
    "        model, param_grid = get_knn_defaults(param_grid)\n",
    "    elif model_name == 'Decision Tree':\n",
    "        model, param_grid = get_decision_tree_defaults(param_grid)\n",
    "    elif model_name == 'Gaussian NB':\n",
    "        model, param_grid = get_gaussian_nb_defaults(param_grid)\n",
    "\n",
    "    clf = GridSearchCV(model, param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)\n",
    "    \n",
    "    # Had to do this because of the annoying warnings of the model\n",
    "    if model_name == 'KNN':\n",
    "        clf.fit(X_train.values, y_train)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best model:')\n",
    "    print(clf.best_estimator_)\n",
    "    print()\n",
    "    \n",
    "    model_process(clf.best_estimator_, model_name, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "    \n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee3cc6-2bab-4fd3-85aa-cd3942e71869",
   "metadata": {},
   "source": [
    "We used some global variables to pass parameters to the inner *xgb_param_optimize* function.\n",
    "\n",
    "It is not the best practice but we used this way to make de code easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2b4bb-77bb-472a-9206-cc43ff203628",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv = 3\n",
    "xgb_scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692d7c7-d227-43b1-bda2-982e31110f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_param_optimize(**kwargs):\n",
    "    \"\"\" The fuction used to optimize the XGBClassifier using the BayesianOptimization Class.\n",
    "    \n",
    "    Arguments:\n",
    "        - kwargs (dict): The dictionary containing the parameters to be optimized and a range of values\n",
    "            that could be used during the optimization process\n",
    "        \n",
    "    Returns:\n",
    "        - score (float): The value of the metric used during the optimization process\n",
    "    \"\"\"\n",
    "    \n",
    "    if kwargs.get('max_depth'):\n",
    "        kwargs['max_depth'] = int(kwargs.get('max_depth'))\n",
    "    if kwargs.get('n_estimators'):\n",
    "        kwargs['n_estimators'] = int(kwargs.get('n_estimators'))\n",
    "\n",
    "    clf = XGBClassifier(use_label_encoder=False, seed=SEED, **kwargs)\n",
    "    \n",
    "    return np.mean(cross_val_score(clf, X_train, y_train, cv=xgb_cv, fit_params={'eval_metric': 'logloss'}, scoring=xgb_scoring, n_jobs=N_JOBS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056c3db-d316-4be8-bacb-417f126b1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_clf_optimize(pbounds, init_points=2, n_iter=3, X_train_local=X_train, y_train_local=y_train):\n",
    "    \"\"\" Helper fuction used to instantiate and call functions of the BayesianOptimization Class for the\n",
    "    XGBClassifier parameters optimization.\n",
    "    \n",
    "    Arguments:\n",
    "        - pbounds (dict): The dictionary containing the parameters to be optimized and a range of values\n",
    "            that could be used during the optimization process\n",
    "        - init_points (int): How many steps of random exploration to be performed\n",
    "        - n_iter (int): How many steps of bayesian optimization to be performed\n",
    "        - X_train_local (pandas DataFrame): The input dataframe to be used to train the machine learning model\n",
    "        - y_train_local (pandas DataFrame): The output values to be predicted by the machine learning model during training\n",
    "        \n",
    "    Returns:\n",
    "        - params (dict): The best parameters to be used with the XGBClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    global X_train\n",
    "    global y_train\n",
    "    \n",
    "    bkp_X_train = X_train.copy()\n",
    "    bkp_y_train = y_train.copy()\n",
    "    \n",
    "    X_train = X_train_local\n",
    "    y_train = y_train_local\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f=xgb_param_optimize,\n",
    "        pbounds=pbounds,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    \n",
    "    optimizer.maximize(\n",
    "        init_points=init_points,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "    \n",
    "    X_train = bkp_X_train\n",
    "    y_train = y_train\n",
    "    \n",
    "    return optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750ff3c-056d-4285-9813-22c2256bed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_with_bayesian(model_name, pbounds={}, scoring='roc_auc', cv=3, init_points=2, n_iter=3,\n",
    "                          X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    \"\"\" Helper function used to optimize the XGBClassifier model and print the performance of the model.\n",
    "    \n",
    "    Arguments:\n",
    "        - model_name (str): The name of the model to be used to print the results of the optimization\n",
    "        - pbounds (dict): The dictionary containing the parameters to be optimized and a range of values\n",
    "            that could be used during the optimization process. If no value is passed, the default values\n",
    "            are going to be used during optimization            \n",
    "        - scoring (str): The metric to be used to evaluate the model\n",
    "            A complete list of the metrics could be found at: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "        - cv (int): Determine the number of folds of the cross validation\n",
    "        - init_points (int): How many steps of random exploration to be performed\n",
    "        - n_iter (int): How many steps of bayesian optimization to be performed\n",
    "        - X_train (pandas DataFrame): The input dataframe to be used to train the machine learning models\n",
    "        - X_test (pandas DataFrame): The input dataframe to be used to test the machine learning models\n",
    "        - y_train (pandas Series): The output values to be predicted by the machine learning models during training\n",
    "        - y_test (pandas Series): The output values to be predicted by the machine learning models during testing\n",
    "        \n",
    "    Returns:\n",
    "        - clf (Machine Learning classifier): The classifier with the best parameter values based on the inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # It is too slow to optimize all of these parameters\n",
    "    # If you are having trouble you could remove some of these\n",
    "    if pbounds == {}:\n",
    "        pbounds = {\n",
    "            'learning_rate': (0.01, 1.0),\n",
    "            'n_estimators': (100, 1000),\n",
    "            'max_depth': (3,10),\n",
    "            'gamma': (0, 5),\n",
    "            'min_child_weight': (1, 10),\n",
    "            'colsample_bytree': (0.5, 1),\n",
    "            'reg_alpha': (0, 10),\n",
    "            'reg_lambda': (0, 10)\n",
    "        }\n",
    "    \n",
    "    global xgb_cv\n",
    "    global xgb_scoring\n",
    "    xgb_cv = cv\n",
    "    xgb_scoring = scoring\n",
    "        \n",
    "    best_params = xgb_clf_optimize(pbounds, init_points, n_iter, X_train_local=X_train, y_train_local=y_train)\n",
    "    params = best_params['params']\n",
    "    \n",
    "    if params.get('max_depth'):\n",
    "        params['max_depth'] = int(params.get('max_depth'))\n",
    "    if params.get('n_estimators'):\n",
    "        params['n_estimators'] = int(params.get('n_estimators'))\n",
    "    \n",
    "    clf = XGBClassifier(use_label_encoder=False, seed=SEED, **params)\n",
    "    \n",
    "    print('Best model:')\n",
    "    print(clf)\n",
    "    print()\n",
    "    \n",
    "    model_process(clf, model_name, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e899f59-f93b-4f21-b166-f9ec4b70a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(model_name, params={}, scoring='roc_auc', cv=3, init_points=2, n_iter=3, n_jobs=N_JOBS,\n",
    "                  X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    \"\"\" Helper function used to optimize the parameters of the machine learning models.\n",
    "    \n",
    "    Arguments:\n",
    "        - model_name (str): The name of the model to be used to get the right machine learning model,\n",
    "            get the right parameters to be optimized and print the results\n",
    "            The acceptables model names are: KNN, Decision Tree, Gaussian NB and XGBoost\n",
    "        - params (dict): The dictionary with the parameters to be used during the optimization. \n",
    "            If no value is passed, the default values are going to be used during optimization.\n",
    "            In case of the XGBoost model, the values of the parameters have to be a range of\n",
    "            possible values\n",
    "        - scoring (str): The metric to be used to evaluate the model\n",
    "            A complete list of the metrics could be found at: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "        - cv (int): Determine the number of folds of the cross validation\n",
    "        - init_points (int): How many steps of random exploration to be performed (Only to XGBoost)\n",
    "        - n_iter (int): How many steps of bayesian optimization to be performed (Only to XGBoost)\n",
    "        - n_jobs (int): The number of jobs to run in parallel. -1 means all processors available\n",
    "        - X_train (pandas DataFrame): The input dataframe to be used to train the machine learning models\n",
    "        - X_test (pandas DataFrame): The input dataframe to be used to test the machine learning models\n",
    "        - y_train (pandas Series): The output values to be predicted by the machine learning models during training\n",
    "        - y_test (pandas Series): The output values to be predicted by the machine learning models during testing\n",
    "        \n",
    "    Returns:\n",
    "        - clf (Machine Learning classifier): The classifier with the best parameter values based on the inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    GRID_SEARCH_MODELS = {'KNN', 'Decision Tree', 'Gaussian NB'}\n",
    "    AVAILABLE_MODELS = GRID_SEARCH_MODELS | {'XGBoost'}\n",
    "    \n",
    "    if model_name not in AVAILABLE_MODELS:\n",
    "        raise ValueError(\"model_name: Must be one of the following values %r.\" % AVAILABLE_MODELS)\n",
    "        \n",
    "    if model_name in GRID_SEARCH_MODELS:\n",
    "        return optimize_with_grid_search(model_name, params, scoring=scoring, cv=cv, n_jobs=n_jobs,\n",
    "                                        X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "    else:\n",
    "        return optimize_with_bayesian(model_name, params, scoring=scoring, cv=cv, init_points=init_points, n_iter=n_iter,\n",
    "                              X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c8183-eb9a-4be9-813b-86d6ec8794ad",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e88fe6-fcac-49c1-bfee-b25f8b856ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = get_best_model('KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66171130-00f1-4b66-9a91-f1339cc34db9",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b44fc-13fd-47a8-ac88-9c8fbd97be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_best = get_best_model('Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa40a4a-f034-4069-8fca-60b99c07f999",
   "metadata": {},
   "source": [
    "**Gaussian NB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa045e-be8a-4981-8a11-0031e0077abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_best = get_best_model('Gaussian NB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d91415-38e4-4aec-8a29-81071cb5665f",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685a528-ca31-4d11-86a8-7580af168c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = get_best_model('XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27690bbd-5fb3-43a0-a624-698f39903cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_table(title='Models Comparison (Optimized)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd0a48-d906-4e9c-b05b-e94e9195375d",
   "metadata": {},
   "source": [
    "# Enhancing the dataset with new ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1334ba6-1dcc-422c-a061-0c8eabd69b2d",
   "metadata": {},
   "source": [
    "The dataset has some few columns that could be used directly to our analysis, so at this part we tried to generate new data to be used by the machine learning algorithms.\n",
    "\n",
    "We tried to create data to specify the difficulty level of each problem/step values. We also created some metric to determine what's the proficiency of the students with math exercises.\n",
    "\n",
    "The defined metrics were very simple, only using the differences betwenn correct and incorrect answers.\n",
    "\n",
    "Because the values of the new columns were created based on the outputs' values (our y) id could cause some bias to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc458cb-d632-44ac-b28f-7d119c6907b9",
   "metadata": {},
   "source": [
    "**Difficulty Level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640387d7-2b9d-4330-b96a-4d698876df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difficulty = df_cleaned[df_cleaned['Outcome'].isin(['CORRECT', 'INCORRECT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d58b04-eaaf-497b-b1eb-f491475639ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difficulty = df_difficulty.groupby(['Problem Name', 'Step Name', 'Outcome']).count()\n",
    "df_difficulty = df_difficulty.iloc[:, 0].unstack().fillna(0)\n",
    "df_difficulty['Difficulty Calc'] = (df_difficulty['CORRECT'] - df_difficulty['INCORRECT'])/ (df_difficulty['CORRECT'] + df_difficulty['INCORRECT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25169781-1291-4e48-b68b-0c5e20b45bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difficulty['Difficulty Calc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5034a-f8a3-4531-afd1-f40bd3f009ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difficulty(x):\n",
    "    \"\"\" Apply some conditions to determine the difficulty of a question based on the value\n",
    "    of the Difficulty Calc column.\n",
    "    \n",
    "    Arguments:\n",
    "        - x (float): The value of the column to be analyzed\n",
    "        \n",
    "    Returns:\n",
    "        - difficulty (str): The string that represents de difficulty of the question\n",
    "    \"\"\"\n",
    "    \n",
    "    if x <= df_difficulty['Difficulty Calc'].quantile(.25):\n",
    "        return 'Hard'\n",
    "    elif x <= df_difficulty['Difficulty Calc'].quantile(.75):\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Easy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612bfd5-7280-4dda-8f9a-494b12784e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difficulty['Difficulty Level'] = df_difficulty['Difficulty Calc'].apply(calculate_difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c99e9b-e31a-436c-b8ea-6e76b39bd819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difficulty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d18ccc-fa09-44ff-8fc6-75e358db06f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for tests\n",
    "# df_cleaned = df_cleaned.drop(columns='Difficulty Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4b9cd-ac01-434c-be87-a33c7c4ee95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.join(df_difficulty['Difficulty Level'], on=['Problem Name', 'Step Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0bbac3-c02d-42b8-986a-d848c5f8e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the Normal difficulty level where we didn't have data to determine\n",
    "# This is probably because there is no data with the response Outcomes or some missing data in the grouping columns\n",
    "df_cleaned['Difficulty Level'] = df_cleaned['Difficulty Level'].fillna('Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba03da6-9124-409f-bae6-30d3adfbed30",
   "metadata": {},
   "source": [
    "**Math Proficiency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30fd02-3174-4639-afd5-26da743dee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proficiency = df_cleaned[df_cleaned['Outcome'].isin(['CORRECT', 'INCORRECT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeafb3-b737-41f5-a09e-66e33e72487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proficiency = df_proficiency.groupby(['Anon Student Id', 'Outcome']).count()\n",
    "df_proficiency = df_proficiency.iloc[:, 0].unstack().fillna(0)\n",
    "df_proficiency['Proficiency Calc'] = (df_proficiency['CORRECT'] - df_proficiency['INCORRECT'])/ (df_proficiency['CORRECT'] + df_proficiency['INCORRECT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73201f6-1f2f-4969-976c-a86b1ed9e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proficiency['Proficiency Calc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49e020-d609-49e1-8456-69391d64de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proficiency(x):\n",
    "    \"\"\" Apply some conditions to determine the proficiency of the student in math\n",
    "    based on the value of the Proficiency Calc column.\n",
    "    \n",
    "    Arguments:\n",
    "        - x (float): The value of the column to be analyzed\n",
    "        \n",
    "    Returns:\n",
    "        - difficulty (str): The string that represents de proficiency of the student\n",
    "    \"\"\"\n",
    "    \n",
    "    if x <= df_proficiency['Proficiency Calc'].quantile(.25):\n",
    "        return 'Low'\n",
    "    elif x <= df_proficiency['Proficiency Calc'].quantile(.75):\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675130ca-2a3a-48e4-97dd-db1a03bb1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proficiency['Proficiency Level'] = df_proficiency['Proficiency Calc'].apply(calculate_proficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0cfb5-4fd6-44c4-a345-e1c92600622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proficiency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b9959-4240-47fe-979a-5bc49635f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for tests\n",
    "# df_cleaned = df_cleaned.drop(columns='Proficiency Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e81685-9102-4b81-a523-5ab76c38d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.join(df_proficiency['Proficiency Level'], on=['Anon Student Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9391cd-af46-4f91-866c-cbf70a403b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the Normal proficiency level where we didn't have data to determine\n",
    "# This is probably because there is no data with the response Outcomes or some missing data in the grouping columns\n",
    "df_cleaned['Proficiency Level'] = df_cleaned['Proficiency Level'].fillna('Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934aa396-b2e0-458a-9dba-0668a12015b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0363ee-30b4-4406-bbfc-d62e386ea720",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_columns = ['Problem Name', 'Step Name', 'Attempt At Step', 'Outcome', 'Last Help Level', 'Difficulty Level', 'Proficiency Level']\n",
    "\n",
    "df_ml, df_filtered = generate_samples(ml_columns, df_cleaned=df_cleaned)\n",
    "df_ml = create_step_dummies(df_ml)\n",
    "df_ml = replace_dtypes(df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405f88c-9edb-4b65-b4d8-56508dcb010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty_dummies = pd.get_dummies(df_ml['Difficulty Level'], prefix='Difficulty')\n",
    "proficiency_dummies = pd.get_dummies(df_ml['Proficiency Level'], prefix='Proficiency')\n",
    "\n",
    "df_ml = pd.concat([df_ml, difficulty_dummies, proficiency_dummies], axis=1)\n",
    "df_ml = df_ml.drop(['Difficulty Level', 'Proficiency Level'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba8e20-fc54-4091-abb4-e44bc7aa2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c050098-fcf0-4102-a3a5-953fc10cefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_create(df_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9399f-626c-4f22-a756-b0832d9b26d5",
   "metadata": {},
   "source": [
    "## Testing the models with the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731fe44-3bc9-4750-9ca1-1feeb97b7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(MultinomialNB(), 'Multinomial NB', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd1082-dd73-463b-8088-d5cb1f83abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = get_best_model('KNN', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23af3b-e0a0-4fcb-b081-0d7222700f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_best = get_best_model('Decision Tree', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbd651-4763-4eed-b415-2140babd1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_best = get_best_model('Gaussian NB', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a9d8c-1327-4d2f-9356-34c31bdbf621",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = get_best_model('XGBoost', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3625a5-eb2f-48fb-a3ea-60e88266a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_table(title='Models Comparison (New Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277f51-8f63-4df0-bb4e-4c5db3625410",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO optimize threshold\n",
    "# https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33b235-9fa8-4845-b0bc-b43aad087051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only the best model from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c54bb7-4d08-403d-965e-8d3b80e6d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gaussian_nb_best.predict_proba(X_test)\n",
    "\n",
    "# Keep probabilities for the positive outcome only\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "# Calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Get the best threshold based on Youden's J statistic\n",
    "J = tpr - fpr\n",
    "idx = np.argmax(J)\n",
    "best_threshold = thresholds[idx]\n",
    "print('Best threshold: {:.4f}'.format(best_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a36c9-d991-4b08-a718-4391ab6f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process(gaussian_nb_best, 'Gaussian NB', threshold=best_threshold, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
